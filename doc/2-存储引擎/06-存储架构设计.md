# 存储架构设计

## 本章概览

在这一章中，我们将了解：

- RocksWrapper 单例：NeoKV 如何封装和初始化 RocksDB
- 8 个 Column Family 的设计：每个 CF 存什么数据、为什么这样配置
- Key 编码体系：MutTableKey / TableKey 的 mem-comparable 编码
- Prefix 与 Bloom Filter 的配合策略
- SplitCompactionFilter：Region Split 后的数据清理
- 关键性能调优参数

**关键文件**：
- `include/engine/rocks_wrapper.h` — RocksWrapper 类定义
- `src/engine/rocks_wrapper.cpp` — 初始化与 CF 配置
- `include/common/mut_table_key.h` — Key 编码器
- `include/common/table_key.h` — Key 解码器
- `include/common/key_encoder.h` — 底层编码工具
- `include/engine/split_compaction_filter.h` — Compaction Filter

## 1. RocksWrapper 单例

NeoKV 的每个 Store 节点只有一个 RocksDB 实例，通过 `RocksWrapper` 单例管理：

```cpp
// include/engine/rocks_wrapper.h
class RocksWrapper {
public:
    static RocksWrapper* get_instance() {
        static RocksWrapper _instance;
        return &_instance;
    }

    int init(const std::string& path);  // 打开/创建数据库

private:
    rocksdb::TransactionDB* _txn_db;    // 主数据库（支持事务）
    bool _is_init = false;              // 防止重复初始化

    // 8 个 Column Family 的 handle
    // 通过 get_handle(cf_index) 访问
};
```

### 1.1 初始化流程

`init()` 方法执行以下步骤：

```
init(path)
    │
    ├─ 1. 配置 DB Options（后台线程数、WAL、统计等）
    │
    ├─ 2. 为每个 CF 配置独立的 ColumnFamilyOptions
    │     （压缩、Bloom Filter、Compaction 策略等）
    │
    ├─ 3. 配置 Block Cache 和 Table Options
    │
    ├─ 4. 打开 TransactionDB
    │     ├─ 已有数据库 → Open（加载现有 CF）
    │     └─ 新数据库 → Open + CreateColumnFamilies
    │
    └─ 5. 设置 _is_init = true
```

NeoKV 使用 `TransactionDB::Open()` 而非普通的 `DB::Open()`，这提供了行级锁和事务支持。事务锁超时配置为 20 秒（`transaction_lock_timeout`），避免死锁时无限等待。

### 1.2 DB 级别配置

```cpp
// src/engine/rocks_wrapper.cpp — init() 中的关键配置
db_options.max_background_jobs = 24;           // 后台线程总数
db_options.max_background_compactions = 20;    // Compaction 线程
db_options.max_background_flushes = 2;         // Flush 线程
db_options.max_subcompactions = 4;             // 单次 Compaction 的并行度
db_options.WAL_ttl_seconds = 600;              // WAL 保留 10 分钟
db_options.max_open_files = 1024;              // 最大打开文件数
db_options.statistics = rocksdb::CreateDBStatistics();  // 启用统计
```

## 2. 八个 Column Family

这是 NeoKV 存储设计的核心。每个 CF 针对其数据特点做了专门的配置：

```
┌─────────────────────────────────────────────────────────────┐
│                      RocksDB 实例                            │
│                                                              │
│  ┌─────────────┐  ┌─────────────┐  ┌──────────────────┐    │
│  │ RAFT_LOG_CF │  │ BIN_LOG_CF  │  │     DATA_CF      │    │
│  │  Raft 日志  │  │   Binlog    │  │  主数据 + 子键    │    │
│  │ 前缀: 9B    │  │ FIFO 策略   │  │  前缀: 16B       │    │
│  └─────────────┘  └─────────────┘  └──────────────────┘    │
│                                                              │
│  ┌─────────────┐  ┌─────────────────┐  ┌────────────────┐  │
│  │ METAINFO_CF │  │REDIS_METADATA_CF│  │REDIS_ZSET_     │  │
│  │ Region 元数据│  │ Redis key 元信息│  │ SCORE_CF       │  │
│  │ 前缀: 1B    │  │ 前缀: 16B      │  │ ZSet 分数索引  │  │
│  └─────────────┘  └─────────────────┘  │ 前缀: 16B      │  │
│                                         └────────────────┘  │
│  ┌─────────────┐  ┌─────────────┐                           │
│  │COLD_DATA_CF │  │COLD_BINLOG  │  (可选，冷存储)           │
│  │             │  │    _CF      │                           │
│  └─────────────┘  └─────────────┘                           │
└─────────────────────────────────────────────────────────────┘
```

### 2.1 RAFT_LOG_CF — Raft 日志

```
用途：存储所有 Region 的 Raft 日志条目、日志元信息、Raft 元数据
```

| 配置项 | 值 | 原因 |
|--------|-----|------|
| Prefix Extractor | `FixedPrefixTransform(9)` | `region_id(8) + type_byte(1)` |
| Compaction Priority | `kOldestLargestSeqFirst` | 优先 compact 最旧的数据（日志是追加写入的） |
| Write Buffer | 128MB × 6 | 较大的 buffer 减少 flush 频率 |
| Compaction Filter | `RaftLogCompactionFilter` | 惰性删除已截断的日志 |

9 字节前缀 = `region_id(8B) + type_byte(1B)`，这让同一 Region 的同类数据（日志条目、元信息）在 Bloom Filter 中共享一个条目，加速前缀查询。

### 2.2 BIN_LOG_CF — Binlog

```
用途：变更数据捕获（CDC），记录数据变更历史
```

| 配置项 | 值 | 原因 |
|--------|-----|------|
| Prefix Extractor | `FixedPrefixTransform(8)` | 时间戳前缀 |
| Compaction Style | **FIFO** | 只保留最近的数据，旧数据自动丢弃 |
| FIFO Max Size | 100GB | 超过后自动删除最旧的 SST 文件 |
| Compression | LZ4 | 日志数据压缩率较好 |

FIFO 策略非常适合 Binlog：我们只关心最近的变更历史，旧数据可以安全丢弃。

### 2.3 DATA_CF — 主数据

```
用途：Redis 子键数据（Hash field、Set member、List element、ZSet member）
      以及旧版 String 编码的数据
```

这是最重要的 CF，配置也最复杂：

| 配置项 | 值 | 原因 |
|--------|-----|------|
| Prefix Extractor | `FixedPrefixTransform(16)` | `region_id(8) + index_id(8)` |
| Memtable Prefix Bloom | 10% ratio | 加速 MemTable 中的前缀查询 |
| Compaction Filter | `SplitCompactionFilter` | Split 后清理超出范围的数据 |
| Compaction Priority | `kMinOverlappingRatio` | 选择与下层重叠最少的文件 compact |
| SST Partitioner | `FixedPrefix(8)` (可选) | SST 文件不跨 Region 边界 |
| L0 压缩 | 无 | L0 文件生命周期短 |
| L1-L6 压缩 | LZ4 | 快速压缩 |
| 底层压缩（可选） | ZSTD + 字典 | 冷数据高压缩率 |
| Auto Compaction | 初始禁用 | 心跳成功后才启用 |

**SST Partitioner** 是一个重要的优化：通过 `FixedPrefixTransform(8)`（即 `region_id`），保证每个 SST 文件只包含一个 Region 的数据。这让 Region Split 后的数据清理更高效——整个 SST 文件可以直接丢弃，而不需要逐条过滤。

**Auto Compaction 初始禁用**：Store 启动时先禁用自动 compaction，等到与 MetaServer 的心跳成功后才启用。这避免了启动阶段 compaction 与 Region 初始化竞争资源。

### 2.4 METAINFO_CF — Region 元数据

```
用途：存储 Region 的边界信息、Peer 列表等元数据
```

| 配置项 | 值 | 原因 |
|--------|-----|------|
| Prefix Extractor | `FixedPrefixTransform(1)` | 1 字节分类前缀 |
| Block Size | 4096B | 元数据量小，用小 block |
| Compaction Priority | `kOldestSmallestSeqFirst` | 优先 compact 最旧最小的文件 |

1 字节前缀用于区分不同类别的元数据（如 Region 信息、Table 信息等），不同前缀字节（0x01-0xFF）代表不同的元数据类型。

### 2.5 REDIS_METADATA_CF — Redis Key 元信息

```
用途：每个 Redis key 的元信息（类型、过期时间、版本号、元素数量）
      String 类型的值也内联存储在这里
```

| 配置项 | 值 | 原因 |
|--------|-----|------|
| Prefix Extractor | `FixedPrefixTransform(16)` | 与 DATA_CF 相同 |
| Memtable Prefix Bloom | 10% ratio | 加速前缀查询 |
| SST Partitioner | `FixedPrefix(8)` (可选) | SST 不跨 Region |
| L0 压缩 | 无 | 同 DATA_CF |
| L1-L6 压缩 | LZ4 | 同 DATA_CF |
| Compaction Filter | 无 | 过期 key 通过读时检查 + TTL Cleaner 处理 |

注意这个 CF **没有** Compaction Filter。过期的 Redis key 通过两种机制清理：
1. **被动过期**：读取时检查 `expire_ms`，过期则视为不存在
2. **主动清理**：`RedisTTLCleaner` 后台线程定期扫描并删除过期 key

### 2.6 REDIS_ZSET_SCORE_CF — ZSet 分数索引

```
用途：Sorted Set 的按分数排序的二级索引
```

配置与 REDIS_METADATA_CF 基本相同。独立 CF 的原因是：ZSet 需要按 member 和按 score 两种顺序访问数据，放在同一个 CF 中会导致迭代器互相干扰。

### 2.7 COLD_DATA_CF / COLD_BINLOG_CF — 冷存储

```
用途：归档数据，可选地存储在远程文件系统（如 AFS）上
```

这两个 CF 在独立的 RocksDB 实例中（`_cold_txn_db`），只在配置了冷存储路径时才启用。冷数据通过 SST Ingestion 导入，使用 `move_files=true` 直接链接远程文件而非复制。

## 3. Key 编码体系

RocksDB 按字节序（lexicographic order）排序 key。为了让业务上的排序需求与字节序一致，NeoKV 设计了一套 **mem-comparable 编码**。

### 3.1 KeyEncoder：底层编码工具

```cpp
// include/common/key_encoder.h

// 有符号整数的 mem-comparable 编码
static uint64_t encode_i64(int64_t val) {
    uint64_t uval = static_cast<uint64_t>(val);
    return uval ^ (1ULL << 63);  // 翻转符号位
}
```

**为什么要翻转符号位？**

有符号整数在二进制补码表示中，负数的最高位是 1，正数是 0。如果直接按字节比较：
- `-1`（0xFFFFFFFFFFFFFFFF）> `1`（0x0000000000000001）❌

翻转符号位后：
- `-1` → 0x7FFFFFFFFFFFFFFF，`1` → 0x8000000000000001
- 0x7F... < 0x80... ✓

再转为大端序（big-endian），就得到了按字节比较等价于数值比较的编码。

完整编码流程：
```
int64_t value
    │
    ├─ XOR 符号位 → uint64_t（保序映射）
    │
    └─ 转大端序 → 8 字节（字节序 = 数值序）
```

### 3.2 MutTableKey：Key 构建器

`MutTableKey` 提供 fluent API 来构建编码后的 key：

```cpp
// include/common/mut_table_key.h
class MutTableKey {
    std::string _data;  // 底层存储

public:
    MutTableKey& append_i64(int64_t val);   // 有符号整数（XOR + 大端）
    MutTableKey& append_u64(uint64_t val);  // 无符号整数（仅大端）
    MutTableKey& append_u32(uint32_t val);
    MutTableKey& append_u16(uint16_t val);
    MutTableKey& append_u8(uint8_t val);
    MutTableKey& append_string(const std::string& val);  // 原始字节
};
```

构建一个 Redis key 的 RocksDB key：

```cpp
MutTableKey key;
key.append_i64(region_id)     // 8 字节，mem-comparable
   .append_i64(index_id)      // 8 字节，mem-comparable
   .append_u16(slot)          // 2 字节，大端
   .append_u32(user_key.size()) // 4 字节，大端
   .append_string(user_key);  // 变长，原始字节
// 总计：18 + 4 + user_key.size() 字节
```

### 3.3 TableKey：Key 解码器

`TableKey` 是只读的 key 解码器，包装 `rocksdb::Slice`：

```cpp
// include/common/table_key.h
class TableKey {
    rocksdb::Slice _data;

public:
    int64_t extract_i64(int pos) const;   // 从 pos 位置解码 int64
    uint64_t extract_u64(int pos) const;
    uint16_t extract_u16(int pos) const;
    uint32_t extract_u32(int pos) const;
};
```

### 3.4 Key 布局总览

NeoKV 中所有 Redis 数据的 key 都遵循统一的前缀格式：

```
┌──────────────────────────────────────────────────────────────┐
│                        RocksDB Key                           │
├──────────┬──────────┬──────┬────────────┬───────┬───────────┤
│region_id │ index_id │ slot │user_key_len│user_key│  suffix   │
│  8 字节  │  8 字节  │2 字节│   4 字节   │ 变长  │  变长     │
├──────────┴──────────┤      │            │       │           │
│   16 字节前缀        │      │            │       │           │
│  (Bloom Filter 粒度) │      │            │       │           │
└─────────────────────┴──────┴────────────┴───────┴───────────┘
```

suffix 部分因 CF 和数据类型而异：
- **DATA_CF（旧编码）**：`[type_tag:1]`
- **REDIS_METADATA_CF**：无 suffix（类型在 value 中）
- **DATA_CF（子键）**：`[version:8][sub_key:变长]`
- **REDIS_ZSET_SCORE_CF**：`[version:8][score:8][member:变长]`

## 4. Prefix 与 Bloom Filter 的配合

每个 CF 的 Prefix Extractor 长度是精心选择的：

| CF | 前缀长度 | 前缀内容 | 含义 |
|----|---------|---------|------|
| RAFT_LOG_CF | 9B | `region_id(8) + type(1)` | 每个 Region 的每种日志类型一个 Bloom 条目 |
| BIN_LOG_CF | 8B | `timestamp(8)` | 按时间前缀过滤 |
| DATA_CF | 16B | `region_id(8) + index_id(8)` | 每个 Region+Table 一个 Bloom 条目 |
| METAINFO_CF | 1B | `category(1)` | 按元数据类别过滤 |
| REDIS_METADATA_CF | 16B | `region_id(8) + index_id(8)` | 同 DATA_CF |
| REDIS_ZSET_SCORE_CF | 16B | `region_id(8) + index_id(8)` | 同 DATA_CF |

**为什么 DATA_CF 的前缀是 16 字节而不是 8 字节？**

如果只用 8 字节（`region_id`），那么同一 Region 内所有 Table 的数据共享一个 Bloom 条目。虽然 NeoKV 当前只有一张表（`__redis__.kv`），但 16 字节前缀为未来扩展留了空间，且不影响当前性能。

**前缀查询的工作方式**：

```cpp
// 查询某个 Region 的某个 key
ReadOptions options;
options.prefix_same_as_start = true;  // 启用前缀过滤

auto* iter = db->NewIterator(options, data_cf);
iter->Seek(prefix);  // Bloom Filter 先过滤不相关的 SST 文件
```

## 5. SplitCompactionFilter

Region Split 后，原 Region 的 key 范围缩小了，但 RocksDB 中仍然存在超出新范围的数据。`SplitCompactionFilter` 在 compaction 时清理这些数据。

### 5.1 工作原理

```cpp
// include/engine/split_compaction_filter.h
class SplitCompactionFilter : public rocksdb::CompactionFilter {
    // region_id → end_key 的映射
    std::map<int64_t, std::string> _region_end_keys;
    std::mutex _mutex;

    bool Filter(int level, const Slice& key, ...) const override {
        // 1. 提取 region_id（前 8 字节）
        int64_t region_id = decode_region_id(key);

        // 2. 查找该 Region 的 end_key
        std::lock_guard<std::mutex> lock(_mutex);
        auto it = _region_end_keys.find(region_id);
        if (it == _region_end_keys.end()) return false;  // 未注册，保留

        // 3. 比较 key 的 suffix（16 字节之后的部分）与 end_key
        Slice suffix(key.data() + 16, key.size() - 16);
        return suffix >= it->second;  // suffix >= end_key → 超出范围，删除
    }
};
```

### 5.2 注册与更新

Region Split 完成后，Store 更新 Filter 中的 end_key：

```cpp
// Region Split 后
SplitCompactionFilter::get_instance()->set_filter_region_info(
    region_id,
    new_end_key,  // Split 后缩小的范围
    ...
);
```

如果 Region 是尾部 Region（`end_key` 为空，表示无上界），则从 Filter 中移除该 Region——不需要过滤。

### 5.3 线程安全

Filter 的 `_region_end_keys` 受 `std::mutex` 保护。虽然 compaction 线程会频繁调用 `Filter()`，但锁的粒度很小（只是一次 map 查找），实际开销可控。

## 6. 性能调优参数

NeoKV 中可通过 gflags 调整的关键存储参数：

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `rocks_block_cache_size_mb` | 8192 (8GB) | Block Cache 大小 |
| `rocks_block_size` | 65536 (64KB) | SST 文件中每个 Block 的大小 |
| `rocks_max_open_files` | 1024 | 最大打开文件数 |
| `max_background_jobs` | 24 | 后台线程总数 |
| `rocks_use_ribbon_filter` | false | 是否使用 Ribbon Filter 替代 Bloom |
| `rocks_use_partitioned_index_filters` | false | 是否使用分区索引和过滤器 |
| `rocks_use_hyper_clock_cache` | false | 是否使用 HyperClockCache 替代 LRU |

## 7. 代码导读

| 文件 | 内容 |
|------|------|
| `include/engine/rocks_wrapper.h` | RocksWrapper 类：单例、CF handle、读写接口 |
| `src/engine/rocks_wrapper.cpp` | 初始化、8 个 CF 的配置、Block Cache、压缩策略 |
| `include/common/key_encoder.h` | 底层编码：大端转换、符号位翻转 |
| `include/common/mut_table_key.h` | MutTableKey：Key 构建器 |
| `include/common/table_key.h` | TableKey：Key 解码器 |
| `include/engine/split_compaction_filter.h` | SplitCompactionFilter：Split 后数据清理 |
| `include/engine/sst_file_writer.h` | SstFileWriter：SST 文件写入封装 |

## 检验你的理解

- NeoKV 所有 Region 共享一个 RocksDB 实例。如果某个 Region 的数据量远大于其他 Region，会对 compaction 产生什么影响？SST Partitioner 如何缓解这个问题？
- `SplitCompactionFilter` 在 compaction 时需要加锁查询 `_region_end_keys`。如果 Region 数量很多（比如 10000 个），这个锁会不会成为瓶颈？有什么优化方案？
- 为什么 REDIS_METADATA_CF 没有 Compaction Filter？如果给它加一个 Filter 来清理过期 key，会有什么好处和风险？
- MutTableKey 使用 `std::string` 作为底层存储。如果改用固定大小的 `std::array`，会有什么优缺点？
- DATA_CF 的 Auto Compaction 在启动时禁用，心跳成功后才启用。如果 MetaServer 长时间不可用，Store 的 DATA_CF 会发生什么？

---

> 下一章：[07-Redis 存储编码](./07-Redis存储编码.md) — 我们将深入 Redis 数据类型在 RocksDB 中的编码方式，包括 Metadata CF、Subkey CF 和 Version-based Lazy Deletion。

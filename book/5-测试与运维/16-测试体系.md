# 测试体系

## 概览

- NeoKV 的两层测试策略：C++ 单元测试与 Go 集成测试
- 为什么用 Go 而不是 C++ 做集成测试
- neo_redis_standalone：一个为测试而生的进程
- 测试基础设施的设计：自动端口分配、进程生命周期、就绪检测
- 如何为新功能添加测试

写完前面十五章，我们已经走过了 NeoKV 从 Raft 共识到 RocksDB 存储、从 Redis 数据结构编码到协议层路由的完整链路。但代码写完不等于做完——如果没有一套可靠的测试来验证这些实现的正确性，所有的精巧设计都只是纸上谈兵。

这一章聊聊 NeoKV 的测试策略。不是"应该怎么测试"的教科书理论，而是我们实际做了什么、为什么这么做、以及这些选择的权衡。

## 两层测试

NeoKV 的测试分两层：**C++ 单元测试**和 **Go 集成测试**。这不是什么新鲜的架构决策，但值得说清楚为什么需要两层。

C++ 单元测试验证的是**内部机制的正确性**——CRC16 的计算结果是否与 Redis 官方实现一致、Key 编解码的往返是否无损、Protobuf 消息的序列化格式是否符合预期。这些测试不启动任何服务进程，编译后直接执行二进制，秒级完成。它们的价值在于快速反馈：改了 slot 计算逻辑，跑一下 `test_redis_slot` 就知道有没有搞砸。

Go 集成测试验证的是**端到端行为的正确性**——一个 Redis 客户端连接到 NeoKV，发送 SET 命令，能不能拿回正确的值？HSET 三个 field 再 HGETALL，返回的 map 对不对？EXPIRE 设置 2 秒后，TTL 是否正确递减？这些测试启动一个真实的 `neo_redis_standalone` 进程，用 `go-redis` 客户端库发送真实的 Redis 命令，验证返回值是否符合 Redis 语义。

两层之间的关系很清晰：单元测试保证**零件**是好的，集成测试保证**组装起来**能跑。我们在实践中遇到过不少情况——编解码的单元测试全绿，但集成测试一跑就挂，因为 Raft apply 层里忘了处理某个边界条件。也遇到过反过来的情况——集成测试全通过，但改了编码格式后单元测试立刻报警，让我们在合并代码前就发现了兼容性问题。

## C++ 单元测试

C++ 测试使用 GTest 框架，文件在 `test/` 目录下。目前有四个测试文件。

**`test_redis_slot.cpp`** 验证 CRC16 和 slot 计算。测试非常简洁，核心就是确认 NeoKV 的 `redis_crc16()` 和 `redis_slot()` 与 Redis 官方实现的计算结果一致。比如字符串 `"123456789"` 的 CRC16 应该是 `0x31C3`，映射到 slot 12739；带 Hash Tag 的 key `"{user1000}.x"` 应该和 `"user1000"` 映射到同一个 slot。这些测试看起来简单，但它们守护着一个关键不变量——如果 slot 计算和 Redis 不一致，NeoKV 声称的"Redis 兼容"就是一句空话。

**`test_redis_codec.cpp`** 验证 Key/Value 的编解码。测试覆盖了编码-解码的完整往返（encode 后 decode 应该得到原始值）、过期时间的编码和判断、TTL 秒数的计算、以及前缀构建的正确性。这些测试直接操作 `RedisCodec` 的 API，不涉及 RocksDB 或 Raft。

**`test_redis_raft.cpp`** 是最大的单元测试文件（约 611 行），覆盖了多个维度。Protobuf 消息测试验证 `OP_REDIS_WRITE` 枚举值、Redis 命令枚举、SET 条件枚举、以及请求消息的序列化和反序列化。扩展编解码测试验证 key 排序保持性（mem-comparable 编码的核心保证）、空 key、二进制 key、大 value 等边界情况。Slot 扩展测试验证 slot 范围 `[0, 16383]`、Hash Tag 的各种边缘情况（空 tag `{}`、嵌套花括号 `{a{b}c}`、无花括号）、以及 CROSSSLOT 检测。压力测试验证 10000 个 key 的编解码性能、500000 个 key 的 slot 分布均匀性、以及 10000 次 Protobuf 序列化的稳定性。

**`test_redis_read_index.cpp`** 是最接近集成测试的 C++ 测试（约 496 行）。它在进程内启动 RocksDB + Raft + Redis 服务，测试完整的读写链路。测试用例包括：Follower 在 ReadIndex 禁用时返回 MOVED 重定向、ReadIndex 启用时返回正确的值、ReadIndex 失败时的降级行为、slot 未被服务时返回 CLUSTERDOWN、SET 命令的语法验证先于路由检查执行、以及一个特别有意思的并发测试——16 个线程同时执行 SET NX，验证只有一个能成功。

构建和运行很简单：

```bash
mkdir -p build && cd build
cmake -DWITH_TESTS=ON ..
make -j$(nproc)

# 运行所有
make test

# 运行单个
./output/bin/test_redis_slot
```

## Go 集成测试

Go 集成测试是 NeoKV 的主要质量保障手段。它覆盖了全部 98 个 Redis 命令的行为验证，测试文件在 `tests/gocase/` 下。

你可能会问：为什么用 Go 写集成测试？C++ 项目用 Go 做测试，不觉得别扭吗？理由其实很务实。第一，`go-redis` 是 Redis 生态里最成熟的客户端库之一，API 干净、类型安全、文档齐全，用它写测试代码的效率远高于用 C++ 的 Redis 客户端（如果有的话）。第二，Go 的测试框架天然支持子测试（`t.Run`）、并行执行、进程管理，这些在 C++ 的 GTest 中需要额外的脚手架代码。第三，也是最重要的——用 Go 客户端测试 NeoKV，和真实用户用各种语言的 Redis SDK 连接 NeoKV 是同一个路径，这让集成测试的可信度更高。

**测试基础设施**在 `tests/gocase/util/` 下，包含几个关键文件：

`server.go` 封装了 `neo_redis_standalone` 进程的生命周期管理。`StartServer()` 函数的逻辑是：先通过 `net.ListenTCP("tcp", "localhost:0")` 获取一个操作系统分配的空闲端口（这个技巧避免了端口冲突——让操作系统选端口，然后立即关掉监听，用这个端口号启动服务）；然后在 workspace 下创建临时数据目录，构建启动命令（传入 `--redis_port`、`--data_dir`、`--leader_timeout_ms=15000` 等参数）；接着读取进程的标准输出，等待 `"NEOKV_READY"` 就绪标记出现（最多等 60 秒）；最后用 `go-redis` 发送 PING 命令再次确认服务可用。

`NeoKVServer` 结构体提供了 `NewClient()` 方法来创建 `go-redis` 客户端，`NewTCPClient()` 创建原始 RESP 协议客户端，以及 `Close()` 方法负责优雅关闭——先发送 SIGTERM 信号，等待最多 30 秒让进程完成清理，如果超时则强制 kill。每个测试 suite 启动一个独立的 `neo_redis_standalone` 实例，测试完成后关闭。这保证了测试之间的完全隔离。

`tcp_client.go` 提供了绕过 `go-redis` 直接操作 RESP 协议的能力。它实现了 `WriteArgs()` 方法将命令编码为 RESP 数组格式并发送，`ReadLine()` 读取一行响应，`MustRead()` 断言下一行等于预期值，`MustReadBulkString()` 读取并断言 RESP Bulk String。这个客户端用在需要测试协议级行为的场景——比如验证 PING 命令的原始响应是 `+PONG\r\n` 而不是被 go-redis 解析后的 Go 字符串。

`flags.go` 定义了三个命令行参数：`-binPath` 指定 `neo_redis_standalone` 二进制路径，`-workspace` 指定测试工作目录，`-deleteOnExit` 控制测试结束后是否清理工作目录。

`assertions.go` 和 `random.go` 提供了一些测试辅助函数：`BetweenValues()` 断言值在 `[start, end]` 范围内，`RandString()` 生成指定长度范围的随机字符串。

**测试 suite** 分布在 `tests/gocase/unit/` 下。每个 suite 是一个 Go 测试函数，在函数开头启动服务器，使用 `defer` 确保测试结束后关闭：

```go
func TestHash(t *testing.T) {
    srv := util.StartServer(t, flagBinPath, flagWorkspace)
    defer srv.Close(t)

    client := srv.NewClient()
    defer client.Close()
    ctx := context.Background()

    t.Run("HSET and HGET", func(t *testing.T) {
        n, err := client.HSet(ctx, "myhash", "field1", "value1").Result()
        require.NoError(t, err)
        require.Equal(t, int64(1), n)

        val, err := client.HGet(ctx, "myhash", "field1").Result()
        require.NoError(t, err)
        require.Equal(t, "value1", val)

        _, err = client.HGet(ctx, "myhash", "nonexist").Result()
        require.Equal(t, redis.Nil, err)
    })
}
```

这种模式非常统一——启动服务、创建客户端、执行命令、验证结果。`t.Run` 让每个子测试有独立的名字和独立的失败报告，跑起来一目了然。

目前有 9 个测试文件，覆盖了所有五种数据类型和通用命令：

| 测试文件 | 覆盖范围 |
|---------|---------|
| `ping/ping_test.go` | PING 命令（TCP 和 go-redis 两种方式） |
| `key/key_test.go` | EXISTS、TYPE、UNLINK、DEL |
| `expire/expire_test.go` | EXPIRE、PEXPIRE、EXPIREAT、PEXPIREAT、TTL、PTTL、PERSIST |
| `type/strings/strings_test.go` | SET、GET、DEL、MSET、MGET、SETNX、SETEX、PSETEX、GETSET、GETDEL、GETEX、STRLEN、APPEND、GETRANGE、SETRANGE |
| `type/strings/string_numeric_test.go` | INCR、DECR、INCRBY、DECRBY、INCRBYFLOAT |
| `type/hash/hash_test.go` | 全部 15 个 Hash 命令 |
| `type/set/set_test.go` | 全部 17 个 Set 命令 |
| `type/list/list_test.go` | 全部 14 个 List 命令 |
| `type/zset/zset_test.go` | 全部 17 个 ZSet 命令 |

测试依赖 `go-redis/v9`（v9.17.3）和 `testify`（v1.11.1），Go 版本要求 1.24+。运行方式：

```bash
cd tests/gocase && mkdir -p workspace

# 运行所有 suite
go test -count=1 ./unit/... \
  -args \
  -binPath=/home/ubuntu/NeoKV/output/bin/neo_redis_standalone \
  -workspace=/home/ubuntu/NeoKV/tests/gocase/workspace

# 运行单个 suite（带详细输出）
go test -count=1 -v ./unit/type/hash/... \
  -args \
  -binPath=/home/ubuntu/NeoKV/output/bin/neo_redis_standalone \
  -workspace=/home/ubuntu/NeoKV/tests/gocase/workspace
```

如果系统的 `go` 不在 PATH 中，可以直接使用 toolchain 路径：`/home/ubuntu/go/pkg/mod/golang.org/toolchain@v0.0.1-go1.24.13.linux-amd64/bin/go test ...`。

## neo_redis_standalone：为测试而生

集成测试的基石是 `neo_redis_standalone`（`src/redis/neo_redis_standalone.cpp`）。它是一个单进程的 NeoKV，内嵌 RocksDB + 单副本 Raft Region，不需要 MetaServer，不需要多节点部署，启动后就是一个功能完整的 Redis 兼容服务。

它的启动流程是这样的：解析命令行参数（`--data_dir`、`--redis_port`、`--raft_port` 等）；初始化 RocksDB（数据目录在 `<data_dir>/rocksdb`）；启动 Raft 服务（如果 `--raft_port=0`，会自动选择空闲端口）；创建一个 Region（ID=1），覆盖全部 16384 个 slot，单副本（`replica_num=1`），这意味着它会立即自动选举为 Leader；初始化 Redis 路由器并构建 SlotTable；最后在 `--redis_port` 上启动 `brpc::RedisService`，等待 Raft Leader 选举完成，向标准输出打印 `NEOKV_READY port=<port>`，然后进入主循环。

单副本 Raft 是一个有趣的退化情况——只有一个节点的 Raft 组，写入只需要自己确认（多数 = 1），不需要等待其他节点。这让 standalone 模式的写入延迟非常低，接近直接写 RocksDB 的水平。但它仍然经过了完整的 Raft 代码路径——日志追加、on_apply 回调、WriteBatch 提交——所以测试覆盖的代码路径和生产环境是一致的。

这个设计决策很关键。我们可以选择"测试模式下绕过 Raft 直接写 RocksDB"来获得更快的测试速度，但那样测试就无法覆盖 Raft apply 层的逻辑——而那恰恰是最容易出 bug 的地方（NX/XX 条件检查、size 更新、version 递增、WriteBatch 原子性等等）。

## 测试覆盖不到的地方

用单副本 standalone 做集成测试，有几个场景是无法覆盖的。了解这些盲区和知道我们能测什么一样重要。

**多副本一致性**。standalone 是单副本，不存在 Leader 和 Follower 之间的数据同步。如果 Raft apply 层写入了额外的或不正确的数据，单副本模式下不会暴露，因为没有其他节点来交叉验证。

**Follower ReadIndex**。standalone 的节点既是 Leader 也是唯一的 Peer，ReadIndex 协议实际上退化为本地读。要测试真正的 ReadIndex 行为，需要至少 3 个节点的集群。不过，C++ 的 `test_redis_read_index` 在一定程度上弥补了这个缺口——它在进程内构建了多节点 Raft 环境来测试 ReadIndex。

**MOVED 重定向**。standalone 只有一个 Region 覆盖所有 slot，不存在"key 不在当前节点服务"的情况。真正的 MOVED 重定向需要多 Region、多节点的集群环境。

**Region 分裂与合并**。这些是 MetaServer 的调度功能，standalone 模式下没有 MetaServer。

**Leader 切换**。单副本不存在选举竞争。如果 apply 层有某些逻辑依赖"本节点是否是 Leader"的判断，这些分支在 standalone 下永远走 Leader 路径。

这些盲区意味着，如果要验证 NeoKV 的分布式特性，需要搭建完整的三节点集群。这也是 NeoKV 作为教学项目未来可以改进的方向——添加一套集群级别的集成测试。

## 如何添加测试

**添加 C++ 单元测试**很直接。在 `test/` 下创建 `test_xxx.cpp`，使用 GTest 的 `TEST()` 或 `TEST_F()` 宏编写测试用例，然后在 `CMakeLists.txt` 中注册测试目标。适合测试编解码、算法、数据结构等不需要启动服务的逻辑。

**添加 Go 集成测试**的标准模式是：在 `tests/gocase/unit/` 下创建目录和 `xxx_test.go` 文件，用 `util.StartServer()` 启动服务器，用 `go-redis` 客户端发送命令并用 `testify` 的 `require` 断言验证结果。需要测试协议级细节时，用 `srv.NewTCPClient()` 获取原始 TCP 连接。

一个典型的新命令测试大概长这样：

```go
package mycommand

import (
    "context"
    "testing"
    "github.com/stretchr/testify/require"
    "tests/gocase/util"
)

var (
    flagBinPath   = util.BinPath()
    flagWorkspace = util.Workspace()
)

func TestMyCommand(t *testing.T) {
    srv := util.StartServer(t, flagBinPath, flagWorkspace)
    defer srv.Close(t)

    client := srv.NewClient()
    defer client.Close()
    ctx := context.Background()

    t.Run("basic behavior", func(t *testing.T) {
        // 准备数据
        require.NoError(t, client.Set(ctx, "key1", "value1", 0).Err())

        // 执行被测命令
        result, err := client.Get(ctx, "key1").Result()
        require.NoError(t, err)
        require.Equal(t, "value1", result)
    })

    t.Run("edge case", func(t *testing.T) {
        // 测试边界情况
    })
}
```

模式非常固定——你只需要关注"发什么命令、期望什么结果"，基础设施会处理服务器的启动、端口分配和清理。

## 检验你的理解

- 为什么 Go 集成测试每个 suite 启动独立的 `neo_redis_standalone` 实例？如果共享一个实例，会引入什么问题？
- `neo_redis_standalone` 使用单副本 Raft。这让哪些场景的测试变得不可能？如果你要测试 MOVED 重定向，需要什么样的测试环境？
- C++ 的 `test_redis_read_index` 能在进程内测试 ReadIndex。为什么不把所有集成测试都改成这种"进程内"的方式？（提示：想想测试的可信度。）
- `fill_cache = false` 是 TTL Cleaner 中的一个优化。你能想到一种测试方法来验证这个优化确实生效了吗？
- 16 个线程并发 SET NX 的测试（`test_redis_read_index.cpp` 中的 `SetNxConcurrentOnlyOneSucceeds`）在验证什么？如果 NX 检查发生在 Handler 层而不是 Raft apply 层，这个测试会失败吗？

---

> 文档到此结束。如果你按照推荐的学习路线阅读到这里，你已经对 NeoKV 的完整架构有了深入的理解——从 Raft 共识到 RocksDB 存储，从 Redis 数据结构编码到协议层路由，再到测试体系如何验证这一切的正确性。
>
> 附录：[命令参考](../6-附录/17-appendix-命令参考.md) — 98 个已实现命令的完整列表与语法说明。
